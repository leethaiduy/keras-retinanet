{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freezing Keras Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Retinanet ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='resnet50_coco_best_v2.1.0.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet import models\n",
    "model = models.load_model(model_path, backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input node    Name: input_1:0 \n",
      "              Shape:(?, ?, ?, 3)\n",
      "Output node   Name: filtered_detections/map/TensorArrayStack/TensorArrayGatherV3:0 \n",
      "              Shape:(?, 300, 4)\n",
      "Output node   Name: filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3:0 \n",
      "              Shape:(?, 300)\n",
      "Output node   Name: filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3:0 \n",
      "              Shape:(?, 300)\n"
     ]
    }
   ],
   "source": [
    "originalInputNode = model.input\n",
    "originalOutputNode = model.output\n",
    "print(\"Input node    Name: {} \\n{}Shape:{}\".format(originalInputNode.name,14*\" \",originalInputNode.shape))\n",
    "for node in originalOutputNode:\n",
    "    print(\"Output node   Name: {} \\n{}Shape:{}\".format(node.name,14*\" \",node.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Static Input Shapes ###\n",
    "### Rename Input ###\n",
    "### Rename Output ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newOutputName=['detection_boxes','detection_scores','detection_classes']\n",
    "newInputName='image_tensor'\n",
    "newInputShape=(1,640,640,3)\n",
    "outPutDir= \"some_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  newInputName!=None and newInputShape!=None:\n",
    "    new_input=Input(batch_shape=newInputShape,name=newInputName)\n",
    "    new_outputs = model(new_input)\n",
    "    new_model = Model(new_input,new_outputs)\n",
    "else:\n",
    "    new_model=Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input node    Name: image_tensor:0 \n",
      "              Shape:(1, 640, 640, 3)\n",
      "Output node   Name: retinanet-bbox/filtered_detections/map/TensorArrayStack/TensorArrayGatherV3:0 \n",
      "              Shape:(1, 300, 4)\n",
      "Output node   Name: retinanet-bbox/filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3:0 \n",
      "              Shape:(1, 300)\n",
      "Output node   Name: retinanet-bbox/filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3:0 \n",
      "              Shape:(1, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input node    Name: {} \\n{}Shape:{}\".format(new_model.input.name,14*\" \",new_model.input.shape))\n",
    "for node in new_model.output:\n",
    "    print(\"Output node   Name: {} \\n{}Shape:{}\".format(node.name,14*\" \",node.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-e87dddd2de4a>:11: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 306 variables.\n",
      "INFO:tensorflow:Converted 306 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "if newOutputName is not None:\n",
    "    num_output = len(new_model.output)\n",
    "    for i in range(num_output):\n",
    "        tf.identity(new_model.outputs[i],name=newOutputName[i])\n",
    "else:\n",
    "    newOutputName=[node.name for node in new_model.outputs]\n",
    "with K.get_session() as sess:\n",
    "    constant_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            sess.graph.as_graph_def(),\n",
    "            newOutputName)\n",
    "    tf.train.write_graph(constant_graph,outPutDir,\"frozen.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-TRT Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names=['detection_boxes','detection_scores','detection_classes']\n",
    "frozen_model_path = './some_directory/frozen.pb'\n",
    "precision = 'FP32'\n",
    "output_dir='./some_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.tensorrt as trt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "def load_pb(pb_path):\n",
    "    \"\"\"Load the TF graph from the pre-build pb file.\"\"\"\n",
    "    print('------------- Load the TF graph from the pre-build pb file: {} -------------'.format(pb_path))\n",
    "    start_time = time.time()\n",
    "    graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(pb_path, 'rb') as pf:\n",
    "        graph_def.ParseFromString(pf.read())\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    print('------------- Load time: {0:.2f} sec'.format(stop_time - start_time))\n",
    "    return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Load the TF graph from the pre-build pb file: ./some_directory/Frozen.pb -------------\n",
      "------------- Load time: 0.27 sec\n"
     ]
    }
   ],
   "source": [
    "frozen_graph=load_pb(frozen_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running against TensorRT version 5.0.2\n"
     ]
    }
   ],
   "source": [
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,\n",
    "    outputs=output_names,\n",
    "    max_batch_size=1,\n",
    "    max_workspace_size_bytes=1<<32,\n",
    "    precision_mode=precision,\n",
    "    minimum_segment_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP16.pb  FP32.pb  Frozen.pb\r\n"
     ]
    }
   ],
   "source": [
    "#!rm './data/Build_trt/fasrcnn_res101/fp16.pb'\n",
    "with open('{}/{}.pb'.format(output_dir,precision), 'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP16.pb  FP32.pb  Frozen.pb\r\n"
     ]
    }
   ],
   "source": [
    "!ls $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-Serving Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pb = './some_directory/FP16.pb'\n",
    "export_dir = './tf_serving_model/retinanet_fp16'\n",
    "map_input = {\"in\":\"image_tensor:0\"}\n",
    "map_output={\"boxes\":\"detection_boxes:0\",\"score\":\"detection_scores:0\",\"classes\":\"detection_classes:0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./tf_serving_model/retinanet_fp16/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./tf_serving_model/retinanet_fp16/saved_model.pb'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "with tf.gfile.GFile(graph_pb, \"rb\") as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "sigs = {}\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    # name=\"\" is important to ensure we don't get spurious prefixing\n",
    "    tf.import_graph_def(graph_def, name=\"\")\n",
    "    g = tf.get_default_graph()\n",
    "#     inp = g.get_tensor_by_name(\"image_tensor:0\")\n",
    "#     boxes = g.get_tensor_by_name(\"detection_boxes:0\")\n",
    "#     num_box = g.get_tensor_by_name(\"num_detections:0\")\n",
    "#     score = g.get_tensor_by_name(\"detection_scores:0\")\n",
    "#     classes = g.get_tensor_by_name(\"detection_classes:0\")\n",
    "    map_input_1 ={key: g.get_tensor_by_name(value) for (key, value) in map_input.items()}\n",
    "    map_output_1 ={key: g.get_tensor_by_name(value) for (key, value) in map_output.items()}\n",
    "    sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \\\n",
    "        tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "            map_input_1,map_output_1)\n",
    "\n",
    "    builder.add_meta_graph_and_variables(sess,\n",
    "                                         [tag_constants.SERVING],\n",
    "                                         signature_def_map=sigs)\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
